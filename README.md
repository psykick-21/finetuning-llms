# Fine-Tuning LLM

Base model: [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) from Hugging Face<br>
Dataset: Hugging Face [IMDb dataset](https://huggingface.co/datasets/stanfordnlp/imdb)<br>
>A random sample of 1000 points each was taken from the train and test data.

Accuracy is used to track model metrics.<br>
The model is fine tuned using LoRA PEFT.<br>


Huge shoutout to [Shaw Talebi](https://www.youtube.com/@ShawhinTalebi/featured)<br>
References:
1. [Fine-tuning Large Language Models (LLMs) | w/ Example Code](https://www.youtube.com/watch?v=eC6Hd1hFvos) by Shaw Talebi
1. Shaw Talebi [GitHub](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning)
